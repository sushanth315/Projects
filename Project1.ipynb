{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB "
      ],
      "metadata": {
        "id": "6jEB3-Gw1Ary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = './train.csv'\n",
        "df = pd.read_csv(train_.csv)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "kBLfShhO3tRV",
        "outputId": "f2728a5b-d383-42f5-882a-af7c2dba2a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9c902821d5f2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./train.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transported_by_age = df.groupby('Age')['Transported'].mean() * 100\n",
        "plt.plot(transported_by_age.index, transported_by_age.values)\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Percent transported')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OLBUebfTTdkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transported_by_age.index, transported_by_age.values)"
      ],
      "metadata": {
        "id": "PSTnRdkxULvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File and Data Field Descriptions\n",
        "\n",
        "    train.csv - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
        "        PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
        "        HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
        "        CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
        "        Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
        "        Destination - The planet the passenger will be debarking to.\n",
        "        Age - The age of the passenger.\n",
        "        VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
        "        RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
        "        Name - The first and last names of the passenger.\n",
        "        Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict."
      ],
      "metadata": {
        "id": "iR5_ojhp4Qg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning and Preprocessing\n",
        "\n",
        "\n",
        "*   Categorical (object) vs Numerical (float64)\n",
        "*   Data types\n",
        "*   Empty, None, NaN\n",
        "\n"
      ],
      "metadata": {
        "id": "GPrptoWe5FrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "vq7WgVEy5JKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "aMxu31a8F36N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df['Transported'].value_counts()\n",
        "plt.pie(counts, labels=counts.index, autopct='%1.1f%%')\n",
        "plt.title('Transported')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nlgcmbqGGC6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "  print(col, df[col].isnull().sum())"
      ],
      "metadata": {
        "id": "Szfl99VX-Jt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "  x=round(df[col].isnull().sum()/len(df)*100, 2)\n",
        "  perc = str(x) + '%'\n",
        "  print(col, df[col].dtype, perc)"
      ],
      "metadata": {
        "id": "MkjHsOES-YNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What to do with Null?\n",
        "*    Replace with mode\n",
        "*    Remove rows with most null values\n",
        "*    Replace with average for continuous, numerical data"
      ],
      "metadata": {
        "id": "luYOP_WS_I7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "QJ0rCllxkl_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize some of the data"
      ],
      "metadata": {
        "id": "QcMpTow8vVBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby(['HomePlanet', 'Transported'])['PassengerId'].count().reset_index()\n",
        "sns.barplot(x='HomePlanet', y='PassengerId', hue='Transported', data=grouped)\n",
        "plt.title('Transported against HomePlanet')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eO7L_LJqvYbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby(['CryoSleep', 'Transported'])['PassengerId'].count().reset_index()\n",
        "sns.barplot(x='CryoSleep', y='PassengerId', hue='Transported', data=grouped)\n",
        "plt.title('Transported against CryoSleep')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yuzlmTozVZQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby(['Destination', 'Transported'])['PassengerId'].count().reset_index()\n",
        "sns.barplot(x='Destination', y='PassengerId', hue='Transported', data=grouped)\n",
        "plt.title('Transported against Destination')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i3xZBq1_VqUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby(['VIP', 'Transported'])['PassengerId'].count().reset_index()\n",
        "sns.barplot(x='VIP', y='PassengerId', hue='Transported', data=grouped)\n",
        "plt.title('Transported against VIP')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YjLPW1AuV_nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='CryoSleep', y='RoomService', data=df)\n",
        "plt.title('RoomService Spendings by CryoSleep') \n",
        "plt.show()\n",
        "sns.boxplot(x='CryoSleep', y='Spa', data=df)\n",
        "plt.title('Spa Spendings by CryoSleep') \n",
        "plt.show()\n",
        "sns.boxplot(x='CryoSleep', y='FoodCourt', data=df)\n",
        "plt.title('FoodCourt Spendings by CryoSleep') \n",
        "plt.show()\n",
        "sns.boxplot(x='CryoSleep', y='ShoppingMall', data=df)\n",
        "plt.title('ShoppingMall Spendings by CryoSleep') \n",
        "plt.show()\n",
        "sns.boxplot(x='CryoSleep', y='VRDeck', data=df)\n",
        "plt.title('VRDeck Spendings by CryoSleep') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MVr6iXQnfcUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='VIP', y='RoomService', data=df)\n",
        "plt.title('RoomService Spendings by VIPStatus') \n",
        "plt.show()\n",
        "sns.boxplot(x='VIP', y='Spa', data=df)\n",
        "plt.title('Spa Spendings by VIPStatus') \n",
        "plt.show()\n",
        "sns.boxplot(x='VIP', y='FoodCourt', data=df)\n",
        "plt.title('FoodCourt Spendings by VIPStatus') \n",
        "plt.show()\n",
        "sns.boxplot(x='VIP', y='ShoppingMall', data=df)\n",
        "plt.title('ShoppingMall Spendings by VIPStatus') \n",
        "plt.show()\n",
        "sns.boxplot(x='VIP', y='VRDeck', data=df)\n",
        "plt.title('VRDeck Spendings by VIPStatus') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2sIb6fUBjhx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='Age', y='RoomService', data=df)\n",
        "plt.title('Age versus Spending')\n",
        "plt.show()\n",
        "sns.scatterplot(x='Age', y='Spa', data=df)\n",
        "plt.title('Age versus Spa')\n",
        "plt.show()\n",
        "sns.scatterplot(x='Age', y='FoodCourt', data=df)\n",
        "plt.title('Age versus FoodCourt')\n",
        "plt.show()\n",
        "sns.scatterplot(x='Age', y='ShoppingMall', data=df)\n",
        "plt.title('Age versus ShoppingMall')\n",
        "plt.show()\n",
        "sns.scatterplot(x='Age', y='VRDeck', data=df)\n",
        "plt.title('Age versus VRDeck')\n",
        "plt.show()\n",
        "\n",
        "g = df['Age'][0]\n",
        "print(g)\n",
        "sns.barplot(x = 'Age',y = 'Transported',data = df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4evTRsoYh5jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "df=pd.read_csv(file) \n",
        "df['GroupSize'] = df['PassengerId'].apply(lambda x: len(df[df['PassengerId'].str.contains(x.split('_')[0])]))\n",
        "\n",
        "df['GroupType'] = np.where(df['GroupSize'] == 1, 'Alone', 'With Others')\n",
        "print(df.head())\n",
        "group_type_counts = df['GroupType'].value_counts()\n",
        "group_type_percentages = group_type_counts / len(df) * 100\n",
        "print(f\"Percentage of passengers traveling alone: {group_type_percentages['Alone']:.2f}%\")\n",
        "print(f\"Percentage of passengers traveling with others: {group_type_percentages['With Others']:.2f}%\")\n",
        "\n",
        "group_transport_counts = df.groupby('GroupType')['Transported'].sum()\n",
        "group_transport_percentages = group_transport_counts / group_type_counts * 100\n",
        "print(f\"Percentage of passengers traveling alone and transported: {group_transport_percentages['Alone']:.2f}%\")\n",
        "print(f\"Percentage of passengers traveling with others and transported: {group_transport_percentages['With Others']:.2f}%\")"
      ],
      "metadata": {
        "id": "EFVvhf2CAQl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean or proportion of transported passengers for each value of groupsize\n",
        "grouped = df.groupby('GroupSize')['Transported'].agg([np.mean, len])\n",
        "grouped['proportion'] = grouped['mean'] * 100\n",
        "\n",
        "# Create a bar plot of the proportion of transported passengers for each value of groupsize\n",
        "plt.bar(grouped.index, grouped['proportion'])\n",
        "plt.xlabel('Group Size')\n",
        "plt.ylabel('Proportion Transported (%)')\n",
        "plt.title('Transported by Group Size')\n",
        "plt.xticks(grouped.index)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PQgVjW95CEIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-100']\n",
        "df['AgeBins'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
        "\n",
        "# calculate the mean or proportion of your boolean variable for each age bin\n",
        "grouped = df.groupby('AgeBins')['Transported'].mean()\n",
        "\n",
        "# create a bar plot to visualize the relationship between age and boolean variable\n",
        "plt.bar(grouped.index, grouped.values)\n",
        "plt.xlabel('Age Bins')\n",
        "plt.ylabel('Mean or Proportion of Boolean Variable')\n",
        "plt.title('Boolean Variable by Age Bins')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GuwHdmvTFf5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('[/ ]', expand=True)\n",
        "grouped = df.groupby(['Deck', 'Transported'])['PassengerId'].count().reset_index()\n",
        "sns.barplot(x='Deck', y='PassengerId', hue='Transported', data=grouped)\n",
        "plt.title('Transported against Deck')\n",
        "plt.show()\n",
        "grouped = df.groupby(['Num', 'Transported'])['PassengerId'].count().reset_index()\n",
        "sns.histplot(data=df, x='Num', hue='Transported')\n",
        "plt.show()\n",
        "grouped = df.groupby(['Side', 'Transported'])['PassengerId'].count().reset_index()\n",
        "sns.barplot(x='Side', y='PassengerId', hue='Transported', data=grouped)\n",
        "plt.title('Transported against Side')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m5ilm0aGoNtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "QS4gVd3xJifj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = './train.csv'\n",
        "df = pd.read_csv(file)\n",
        "test_file = './test.csv'\n",
        "test_df = pd.read_csv(test_file)"
      ],
      "metadata": {
        "id": "_dJU0IILJm8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('[/ ]', expand=True)\n",
        "df['GroupSize'] = df['PassengerId'].apply(lambda x: len(df[df['PassengerId'].str.contains(x.split('_')[0])]))\n",
        "df = df.drop(columns = ['Cabin','Name', 'PassengerId', 'Num'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "j5fDKa0lJu9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[['Deck', 'Num', 'Side']] = test_df['Cabin'].str.split('[/ ]', expand=True)\n",
        "test_df['GroupSize'] = test_df['PassengerId'].apply(lambda x: len(test_df[test_df['PassengerId'].str.contains(x.split('_')[0])]))\n",
        "test_df = test_df.drop(columns = ['Cabin','Name','PassengerId', 'Num'])\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "qr_1LE_7kXjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill in missing values"
      ],
      "metadata": {
        "id": "w_ynWuP4ML73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cryo_mode = df['CryoSleep'].mode()[0]\n",
        "df.loc[df['VRDeck'] > 0, 'CryoSleep'] = False\n",
        "df.loc[df['VRDeck'] == 0, 'CryoSleep'] = True\n",
        "df.loc[df['VRDeck'].isna(), 'CryoSleep'] = cryo_mode\n",
        "\n",
        "for col in ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']:\n",
        "  df['missing_spending'] = np.where(df['CryoSleep'] == True, 0, np.nan)\n",
        "  df[col] = np.where(df['missing_spending'].isna(), df[col], df['missing_spending'])\n",
        "  df.drop('missing_spending', axis=1, inplace=True)\n",
        "\n",
        "for column in ['Age', 'Spa','VRDeck', 'RoomService', 'ShoppingMall', 'FoodCourt']:\n",
        "    df[column] = df[column].fillna(df[column].mean())\n",
        "\n",
        "for column in ['CryoSleep', 'HomePlanet', 'Side', 'Deck', 'Destination', 'VIP']:\n",
        "    df[column] = df[column].fillna(df[column].mode()[0])\n",
        "\n",
        "for column in ['Age']:\n",
        "    df[column] = df[column]/df[column].max()\n",
        "\n",
        "for col in ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']:\n",
        "    df[col]=np.log(1+df[col])      "
      ],
      "metadata": {
        "id": "bVwbl1f5JlJN",
        "outputId": "f786b5f8-7aaa-4f49-b6ec-d44ae488694e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f46d89404d51>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcryo_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CryoSleep'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VRDeck'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CryoSleep'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VRDeck'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CryoSleep'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VRDeck'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CryoSleep'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcryo_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cryo_mode = test_df['CryoSleep'].mode()[0]\n",
        "test_df.loc[test_df['VRDeck'] > 0, 'CryoSleep'] = False\n",
        "test_df.loc[test_df['VRDeck'] == 0, 'CryoSleep'] = True\n",
        "test_df.loc[test_df['VRDeck'].isna(), 'CryoSleep'] = cryo_mode\n",
        "\n",
        "for col in ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']:\n",
        "  test_df['missing_spending'] = np.where(test_df['CryoSleep'] == True, 0, np.nan)\n",
        "  test_df[col] = np.where(test_df['missing_spending'].isna(), test_df[col], test_df['missing_spending'])\n",
        "  test_df.drop('missing_spending', axis=1, inplace=True)\n",
        "\n",
        "for column in ['Age', 'Spa','VRDeck', 'RoomService', 'ShoppingMall', 'FoodCourt']:\n",
        "    test_df[column] = test_df[column].fillna(test_df[column].mean())\n",
        "\n",
        "for column in ['CryoSleep', 'HomePlanet', 'Side', 'Deck', 'Destination', 'VIP']:\n",
        "    test_df[column] = test_df[column].fillna(test_df[column].mode()[0])\n",
        "\n",
        "for column in ['Age']:\n",
        "    test_df[column] = test_df[column]/test_df[column].max()\n",
        "\n",
        "for col in ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']:\n",
        "    test_df[col]=np.log(1+test_df[col])    "
      ],
      "metadata": {
        "id": "YIT8jqzHkl36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['HomePlanet', 'CryoSleep', 'Side', 'Deck', 'Destination',], prefix = ['HomePlanet', 'CryoSleep', 'Side', 'Deck', 'Destination',])"
      ],
      "metadata": {
        "id": "fJcxNq7jXoXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.get_dummies(test_df, columns=['HomePlanet', 'CryoSleep', 'Side', 'Deck', 'Destination',], prefix = ['HomePlanet', 'CryoSleep', 'Side', 'Deck', 'Destination',])"
      ],
      "metadata": {
        "id": "vU6wT1k_k1ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_total = df.drop('Transported', axis=1)\n",
        "y_train_total = df['Transported']"
      ],
      "metadata": {
        "id": "6ZImicaHNtw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X_train_total = X_train_total.astype(np.float32)\n",
        "tensor_x = tf.convert_to_tensor(X_train_total)\n",
        "\n",
        "y_train_total = y_train_total.astype(np.float32)\n",
        "tensor_y = tf.convert_to_tensor(y_train_total)\n",
        "\n",
        "test_df = test_df.astype(np.float32)\n",
        "tensor_test = tf.convert_to_tensor(test_df)"
      ],
      "metadata": {
        "id": "Gl36YsZ1Wt9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train.shape[1]\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, input_shape=(num_features,), activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(tensor_x, tensor_y, epochs=30, batch_size=32)"
      ],
      "metadata": {
        "id": "feaLue8GWANq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create_model(optimizer='adam', activation='relu', num_hidden_layers=1, num_units=32):\n",
        "    model = keras.Sequential()\n",
        "    for i in range(num_hidden_layers):\n",
        "        model.add(keras.layers.Dense(units=num_units, activation=activation))\n",
        "    model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32)\n",
        "param_grid = {\n",
        "    'optimizer': ['adam', 'rmsprop'],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'num_hidden_layers': [1, 2],\n",
        "    'num_units': [32, 64]\n",
        "}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train_total, y_train_total)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "id": "5xw3GZTHaUdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(tensor_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(bool)\n",
        "print(y_pred_binary)"
      ],
      "metadata": {
        "id": "LTEvj389Ya74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_binary = [item for sublist in y_pred_binary for item in sublist]\n",
        "cpy = pd.read_csv(test_file)\n",
        "d = {'PassengerId': cpy['PassengerId'], 'Transported': y_pred_binary}\n",
        "df_sub= pd.DataFrame(data=d)\n",
        "df_sub.to_csv('submission-2.csv',index = False)\n",
        "df_sub"
      ],
      "metadata": {
        "id": "VJK07vteZNjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "Lljc5goJgbFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.03, 0.05],\n",
        "    'depth': [4, 6, 8],\n",
        "    'l2_leaf_reg': [1, 3, 5],\n",
        "    'iterations': [100, 200, 300],\n",
        "    'loss_function': ['Logloss', 'CrossEntropy'],\n",
        "    'eval_metric': ['AUC'],\n",
        "    'random_seed': [42]\n",
        "}\n",
        "\n",
        "catboost = CatBoostClassifier()\n",
        "grid_search = GridSearchCV(catboost, param_grid, cv=5, scoring='roc_auc')\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Validation score: {:.2f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "6tfNqFV7gDN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Validation score: {:.2f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "5EBty0wxj5Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "cat = CatBoostClassifier(depth=6,eval_metric='AUC', iterations=300, l2_leaf_reg=1, learning_rate=0.05, loss_function='Logloss', random_seed=42)\n",
        "cat.fit(X_train, y_train)\n",
        "test_pred = cat.predict(test_df)"
      ],
      "metadata": {
        "id": "q-anQHYqk9pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat.predict(X_train)"
      ],
      "metadata": {
        "id": "RTAbiO1E0A53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpy = pd.read_csv(test_file)\n",
        "d = {'PassengerId': cpy['PassengerId'], 'Transported': test_pred}\n",
        "df_sub= pd.DataFrame(data=d)\n",
        "df_sub.to_csv('submission-2.csv',index = False)\n",
        "df_sub"
      ],
      "metadata": {
        "id": "QrKiHfGGmR5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'none'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
        "    'l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
        "}\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "grid_search = GridSearchCV(lr_model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Validation score: {:.2f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "DyiAtcRiW-RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Validation score: {:.2f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "k60EBrAogSXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(C=1000).fit(X_train, y_train)\n",
        "train_pred = clf.predict(X_train)\n",
        "clf.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "_OxIJyAeYIzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Stacking\n"
      ],
      "metadata": {
        "id": "a3gmP_F4a2vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "estimators = [\n",
        "   ('lr', LogisticRegression(C=0.001, l1_ratio=0, multi_class='auto', penalty='none')),\n",
        "   ('ct', CatBoostClassifier(depth=6,eval_metric='AUC', iterations=300, l2_leaf_reg=1, learning_rate=0.05, loss_function='Logloss', random_seed=42)),\n",
        "   ('kn', KNeighborsClassifier(n_neighbors=15)),\n",
        "   ('dt', DecisionTreeClassifier(max_depth=7)),\n",
        "   ('rf', RandomForestClassifier(max_depth=7, n_estimators=100))\n",
        "]\n",
        "clf = StackingClassifier(\n",
        "estimators=estimators, final_estimator=LogisticRegression()\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "X_train_total, y_train_total, stratify=y_train_total, random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "ZNe-xvuka6Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'solver': ['svd', 'lsqr', 'eigen'],\n",
        "    'shrinkage': [None, 'auto', 0.1, 0.2, 0.3],\n",
        "    'n_components': [None, 1, 2, 3]\n",
        "}\n",
        "\n",
        "# Create an LDA classifier\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(lda, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model found\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "e-3mBcQA6NQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = clf.predict(test_df)\n",
        "cpy = pd.read_csv(test_file)\n",
        "d = {'PassengerId': cpy['PassengerId'], 'Transported': test_pred}\n",
        "df_sub= pd.DataFrame(data=d)\n",
        "df_sub.to_csv('submission-2.csv',index = False)\n",
        "df_sub"
      ],
      "metadata": {
        "id": "8HFq4CKdlVx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEFMYrmP07Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn_range = list(range(1,11))\n",
        "parameters = dict(n_neighbors=knn_range)\n",
        "grid = GridSearchCV(knn, parameters, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
        "grid_search = grid.fit(X_train, y_train)\n",
        "accuracy = grid_search.best_score_ *100"
      ],
      "metadata": {
        "id": "IXSw6k3pKgA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy is: \", accuracy)"
      ],
      "metadata": {
        "id": "kYRzTCEIKiIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}